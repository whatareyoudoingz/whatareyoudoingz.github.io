---
title: 2023 [Easy Study Project X 이지스퍼블리싱] BDA 학회 딥러닝 스터디 4주차 8&9
tags: [2023, BDA, RNN, 생성모델]
author: Jins
---

# Summary
한 달 동안 "Do it! 딥러닝 교과서"를 가지고 진행한 BDA 내부 스터디가 이번주 8,9단원을 공부하며 벌써 막바지에 왔다. 

포스팅할 내용은 8단원은 순환 신경망에 대한 내용이고, 9단원은 생성 모델이다.

<br/>

# **Content**

<br/>

## **순환 신경망**

8단원은 가변 길이의 데이터 순서를 고려하여 문맥을 형성하고 예측하는 인공 신경망인 순환 신경망에 대해 공부한다.큰 흐름을 파악할 수 있는 내용 요약은 다음과 같다. 

- 순차 데이터 : 시간과 공간의 순서 관게를 가지는 데이터
    - 시간 순서 : 자연 현상, 음악과 소리, 움직임과 운동, 동영상과 애니메이션, 주가/경제 지표 트렌드, 심전도, 뇌파 등
    - 공간 순서 : 글, 악보, 염기서열, 프로그램

<br/>

- 기억을 갖는 인공 신경망 : **홉필드 네트워크**
    - 의미 : 새로운 입력이 특정 패턴으로 수렴(1,-1의 벡터)하게 만들어 **기억해둔 패턴을 연상**하는 네트워크
    - 목적 : 미리 기억해둔  패턴 연상
    - 가중치와 편향 사전에 계산
    - 입력 데이터가 양극화될 때까지 출력을 입력으로 무한 피드백하여 순환 연산, 출력이 특정 패턴과 같아지면 피드백 멈춤.
    <img width="521" alt="스크린샷 2023-06-05 오후 6 52 13" src="https://github.com/whatareyoudoingz/whatareyoudoingz/assets/108795647/1e153298-6897-47f7-a19a-99e49277a760">

<br/>

- 기억을 전달하는 인공 신경망 : **순환 신경망** 
    - 구조
    <img width="492" alt="스크린샷 2023-06-05 오후 7 13 57" src="https://github.com/whatareyoudoingz/whatareyoudoingz/assets/108795647/b99c6e0b-bf9d-4f38-9595-9cedfd47798c">
    - 계산 그래프
    <img width="447" alt="스크린샷 2023-06-05 오후 7 13 06" src="https://github.com/whatareyoudoingz/whatareyoudoingz/assets/108795647/28f78eea-51c4-4512-bc51-3a675296d721">
    - **가중치를 공유**하는 이유
        - 특정 순차 구조가 위치에 상관없이 포착됨
        - 가변 길이를 가지는 데이터에 유연하게 대처함
        - 파라미터를 공유하면서 파라미터 수를 절약할 수 있고, 정규화 효과가 생김
    - 주요 모델
        - 입,출력의 순차열 여부 : 일대다, 다대일, 다대다
            - 일대다 : 이미지 캡션
            - 다대일 : 감성 분석 (영화 평론 긍,부정 여부)
            - 다대다 : 동영상 프레임별 분류
        - 입력 데이터 탐색 방향 : 양방향
            - 양방향 : 기계 번역
        - 입출력의 길이가 다른 순차열 데이터 : 인코더-디코더
            - 인코더-디코더 (Seq2Seq모델) : 기계 번역, 오디오 데이터를 동영상으로 변환
    - 역전파 알고리즘 적용 : **BPTT**(=BackPropagation Through Time=시간펼침 역전파)
        - 한계 : 끝이 없거나 아주 긴 순차열 데이터에는 적용할 수 없음.
        <img width="402" alt="스크린샷 2023-06-05 오후 7 44 28" src="https://github.com/whatareyoudoingz/whatareyoudoingz/assets/108795647/4efb5aa5-3310-4373-838a-4af4452a553e">
        - 한계 극복 : **Truncated BPTT**(=절단 시간펼침 역전파)
            - 끝이 없는 순차열, 아주 긴 순차열 데이터에 적용가능
            <img width="403" alt="스크린샷 2023-06-05 오후 7 44 49" src="https://github.com/whatareyoudoingz/whatareyoudoingz/assets/108795647/e5b4cb26-ca07-4a9b-a2db-50d2e045d5f8">
    - 한계 
        - 최적화가 어렵고 성능적인 한계가 존재한다.
        - 장기의존성 문제 : context 범위가 넓을 때 멀리 떨어진 입력에 대한 의존성이 있음에도 불구하고 입력의 영향이 점점 사라지는 현상
        - 그레디언트 소실과 폭발 : 학습하면서 그레이디언트가 없어지거나 발산하는 현상
    - 한계 극복 => **셀 구조 순환 신경망 등장**
        - LSTM 
            - 셀 구조
                <img width="346" alt="스크린샷 2023-06-05 오후 8 03 55" src="https://github.com/whatareyoudoingz/whatareyoudoingz/assets/108795647/92f2e863-e99e-46cf-a7f2-ac8d560ad676">
        - GRU : LSTM장점 유지, 게이트 구조 단순화
            - 셀 구조
                <img width="245" alt="스크린샷 2023-06-05 오후 8 04 31" src="https://github.com/whatareyoudoingz/whatareyoudoingz/assets/108795647/b3e82339-f026-4461-8517-2c04f2fd1c7f">
- 순차 데이터를 다루는 다른 구조의 모델 : 어텐션, 시간 팽창 Convolution

<br/>

---


## **생성 모델**

9장은 비지도 학습 방법인 생성 모델에 대해 공부한다. 큰 흐름을 파악할 수 있는 내용 요약은 다음과 같다. 

- 생성 모델 : 비지도 학습 방법
    - 훈련 데이터의 확률분포를 추정해서 새로운 데이터를 생성하는 모델
    - 사용 종류
        - 새로운 객체 생성 (**새로운 예술 작품 생성**, 이미지 변환, 데이터 증강 등)
        - 이상 데이터 탐지
        - 잠재 공간에서 데이터 표현 학습
        - 강화 학습에서 미래의 상태 및 행동에 대한 시계열 데이터 생성
    - 종류 (기준 : 확률분포의 추정 방식)
        - 명시적 모델 : VAE(=Variational AutoEncoder=오토 인코더)
        - 암묵적 모델 : **GAN**(=Generative Adversarial Network=적대적 생성 신경망)
            - 생성자와 판별자가 경쟁하면서 훈련한다. 
            <img width="352" alt="스크린샷 2023-06-05 오후 8 42 46" src="https://github.com/whatareyoudoingz/whatareyoudoingz/assets/108795647/a5916dcc-f404-45f3-ac67-af91fe5cc0be">
            -발전된 GAN 
                - 화질 개선 : DCGAN, WGAN, PGGAN
                - Pix2Pix(CGAN)
---

<br/>

# **회고**
공부를 하면서 전공시간에 배웠던 내용들이 다시 생각나면서 그동안 들었던 수업과 필기들이 빛을 발하는 순간들이었고, 덕분에 잊고 있던 개념들을 다시 복기할 수 있어 좋았다. 그리고 더 나아가 새로운 기술들에 대해 배우고, 실습 문제를 통해 적용해 볼 수 있어 좋았다. 

그동안 처음 개념에 대해서 배웠을 때는 막연하게 공부하다보니 안다고 할 수 없었는데 스터디를 통해 책을 다시 공부하고 공부했던 내용들을 찾아보면서 그동안의 공부 내용들이 연결되는 느낌을 받았고, 이제서야 안다고 할 수 있겠다는 자신감이 생기기 시작했다. 

스터디 기간이 짧다보니 모든 내용을 가지고 가지는 못했던 것 같아 스터디가 끝나고 다시 천천히 공부하여 그동안의 공부 내용들과 연결짓는 작업을 해야겠다!!